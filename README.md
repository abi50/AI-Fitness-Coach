# ğŸ‹ï¸â€â™€ï¸ AI Fitness Coach --- Action Recognition

Recognize fitness exercises from videos using **skeleton landmarks** and
a **stacked LSTM** model.\
Phase 1: classify the movement.\
Phase 2 (planned): evaluate execution quality.

------------------------------------------------------------------------

## ğŸ“¦ Tech Stack

-   **Python 3.11+**
-   **TensorFlow / Keras**
-   **MediaPipe** (pose landmarks extraction)
-   NumPy, Pandas, scikit-learn, Matplotlib
-   Jupyter (for exploration)

------------------------------------------------------------------------

## ğŸ—‚ Project Structure

. â”œâ”€ configs/ \# YAML/JSON configs (training, paths, hyperâ€‘params) â”œâ”€
data/ \# raw/processed data (ignored by git) â”œâ”€ models/ \# saved
checkpoints / exported models (ignored by git) â”œâ”€ notebooks/ \# EDA,
experiments â”œâ”€ src/ \# package code (dataloaders, model, train, infer)
â”œâ”€ utils/ \# helpers (metrics, viz, io) â””â”€ README.md

> ×”×¢×¨×”: `data/` ×•Ö¾`models/` ××•×—×¨×’×™× ×‘â€‘`.gitignore`.

------------------------------------------------------------------------

## âš™ï¸ How It Works

1.  **Data Extraction** --- MediaPipe Pose â†’ perâ€‘frame joint
    coordinates.\
2.  **Preprocessing** --- normalization to a reference joint, sequence
    **padding** to max length, and a **Masking** layer to ignore padded
    frames.\
3.  **Model** --- Input (T Ã— J Ã— C) â†’ Masking â†’ **LSTM Ã—2** â†’ Dense â†’
    **Softmax** over exercise classes.\
4.  **Pipeline** --- `tf.data` for streaming miniâ€‘batches with low
    memory footprint.

------------------------------------------------------------------------

## ğŸš€ Quickstart

### 1) Environment

``` bash
python -m venv .venv
# Windows:
.venv\Scripts\activate
# Linux/Mac:
source .venv/bin/activate

pip install -r requirements.txt
```

### 2) Configure

Create a config (e.g.Â configs/train.yaml):

``` yaml
data:
  train_dir: data/train
  val_dir: data/val
  classes: ["squat", "pushup", "lunge", "jumping_jack"]
  max_seq_len: 240
preprocess:
  normalize: true
  center_joint: "hip_center"
train:
  batch_size: 16
  epochs: 30
  lr: 1e-3
  optimizer: adam
model:
  lstm_units: [128, 64]
  dropout: 0.3
  dense: 64
  seed: 42
paths:
  checkpoints: models/checkpoints
  exports: models/exports
```

### 3) Landmark Extraction (example)

``` bash
python -m src.scripts.extract_landmarks   --videos_dir data/raw/videos   --out_dir data/processed/landmarks
```

### 4) Train

``` bash
python -m src.train --config configs/train.yaml
```

### 5) Evaluate

``` bash
python -m src.eval --ckpt models/checkpoints/best.ckpt --split val
```

### 6) Inference (single video)

``` bash
python -m src.infer   --video path/to/video.mp4   --ckpt models/checkpoints/best.ckpt
```

------------------------------------------------------------------------

## ğŸ§ª Model Details

-   **Input**: sequence of frames, each frame = joints Ã—
    (x,y\[,z,visibility\]).\
-   **Masking**: skips padded frames, so batches can mix different
    sequence lengths.\
-   **Temporal modeling**: two stacked LSTMs capture motion dynamics.\
-   **Output**: class probabilities.

------------------------------------------------------------------------

## ğŸ› ï¸ Challenges & Solutions

-   Variable sequence length â†’ padding + masking.\
-   Hardware limits â†’ small batches + tf.data streaming.\
-   Training stability â†’ coordinate normalization & dropout.

------------------------------------------------------------------------

## ğŸ“Š Results (current)

Correctly classifies major exercises from skeleton data.\
Serves as the base for Phase 2: form/quality assessment.

××¤×©×¨ ×œ×”×•×¡×™×£ ×›××Ÿ ×˜×‘×œ×” ×¢× Accuracy/Precision/Recall ×× ×™×©.

------------------------------------------------------------------------

## ğŸ”® Roadmap

-   âœ… Phase 1 --- movement classification\
-   â³ Phase 2 --- executionâ€‘quality scoring (perâ€‘rep feedback)\
-   â³ Larger, more diverse dataset & realâ€‘time optimization

------------------------------------------------------------------------

## ğŸ” Notes

-   Do not commit data, models or secrets. Keep only \*.example files in
    version control.\
-   Reâ€‘generate/rotate any key that was ever committed by mistake.

------------------------------------------------------------------------

## ğŸ‘©â€ğŸ’» Author

Developed by Abigail Berk.
